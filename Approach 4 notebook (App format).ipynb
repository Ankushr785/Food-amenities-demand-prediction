{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Akai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#data preparation\n",
    "\n",
    "data = pd.read_csv('/home/Akai/Documents/dataset.csv')\n",
    "data = data.fillna(method='bfill', axis=0)\n",
    "\n",
    "act_demand = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data.CustomerCount[i] = data.CustomerCount[i] + data.MissedCust[i]\n",
    "    act_demand.append(data.OrderedQty[i] + data.MissedDemand[i])\n",
    "    \n",
    "data['ActualDemand'] = pd.DataFrame({'ActualDemand':act_demand})\n",
    "\n",
    "spe_data = data[data.SkuId == 64].reset_index(drop=True)\n",
    "\n",
    "\n",
    "for i in range(len(spe_data)):\n",
    "    if spe_data.CustomerCount[i]<np.percentile(spe_data.CustomerCount, 3):\n",
    "        spe_data.CustomerCount[i]=np.percentile(spe_data.CustomerCount, 3)\n",
    "    elif spe_data.CustomerCount[i]>np.percentile(spe_data.CustomerCount, 97):\n",
    "        spe_data.CustomerCount[i]=np.percentile(spe_data.CustomerCount, 97)\n",
    "    else:\n",
    "        riario=0\n",
    "    if spe_data.ActualDemand[i]<np.percentile(spe_data.ActualDemand, 3):\n",
    "        spe_data.ActualDemand[i]=np.percentile(spe_data.ActualDemand, 3)\n",
    "    elif spe_data.ActualDemand[i]>np.percentile(spe_data.ActualDemand, 97):\n",
    "        spe_data.ActualDemand[i]=np.percentile(spe_data.ActualDemand, 97)\n",
    "    else:\n",
    "        count=0\n",
    "        \n",
    "onion_data = data[data.SKUName == 'Onion'].reset_index(drop=True)\n",
    "dummy_variable1 = onion_data.AvgSP\n",
    "\n",
    "#converting weekdays to categories\n",
    "\n",
    "ordered = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "spe_data.WeekDay = spe_data.WeekDay.astype(\"category\", ordered=True, categories=ordered).cat.codes\n",
    "\n",
    "#Setting train quantity\n",
    "\n",
    "step = 5\n",
    "r = len(spe_data)-step\n",
    "\n",
    "#creating input_variables and output_variable\n",
    "\n",
    "input_variables = pd.DataFrame({'Date':spe_data.DeliveryDate, 'CustomerCount':spe_data.CustomerCount, 'AvgSP':spe_data.AvgSP,  'OP':dummy_variable1})\n",
    "input_variables = input_variables.drop(labels = ['Date'], axis=1)\n",
    "\n",
    "output_variable = pd.DataFrame({'Date':spe_data.DeliveryDate, 'ActualDemand':spe_data.ActualDemand})\n",
    "output_variable = output_variable.drop(labels = ['Date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting up LSTM environment\n",
    "\n",
    "#frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = pd.concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn pd.Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = np.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting AvgSP\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#AvgSP series\n",
    "series_asp = input_variables['AvgSP']\n",
    "\n",
    "# transform data to be stationary\n",
    "raw_values_asp = series_asp.values\n",
    "diff_values_asp = difference(raw_values_asp, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised_asp = timeseries_to_supervised(diff_values_asp, 1)\n",
    "supervised_values_asp = supervised_asp.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train_asp, test_asp = supervised_values_asp[0:-step], supervised_values_asp[-step:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler_asp, train_scaled_asp, test_scaled_asp = scale(train_asp, test_asp)\n",
    "\n",
    "# fit the model\n",
    "lstm_model_asp = fit_lstm(train_scaled_asp, 1, 100, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped_asp = train_scaled_asp[:, 0].reshape(len(train_scaled_asp), 1, 1)\n",
    "train_fit_asp = lstm_model_asp.predict(train_reshaped_asp, batch_size=1)\n",
    "\n",
    "train_reshaped_asp1 = []\n",
    "for i in range(len(train_fit_asp)):\n",
    "    train_reshaped_asp1.append(train_reshaped_asp[i][0])\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions_asp = list()\n",
    "for i in range(len(test_scaled_asp)):\n",
    "\t# make one-step forecast\n",
    "\tX_asp, y_asp = test_scaled_asp[i, 0:-1], test_scaled_asp[i, -1]\n",
    "\tyhat_asp = forecast_lstm(lstm_model_asp, 1, X_asp)\n",
    "\t# invert scaling\n",
    "\tyhat_asp = invert_scale(scaler_asp, X_asp, yhat_asp)\n",
    "\t# invert differencing\n",
    "\tyhat_asp = inverse_difference(raw_values_asp, yhat_asp, len(test_scaled_asp)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions_asp.append(yhat_asp)\n",
    "\texpected_asp = raw_values_asp[len(train_asp) + i + 1]\n",
    "\tprint('Day=%d, Predicted_asp=%f, Expected_asp=%f' % (i+1, yhat_asp, expected_asp))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values_asp[-step:], predictions_asp))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# line plot of observed vs predicted\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(train_reshaped_asp1, color = 'blue', label = 'actual_values')\n",
    "plt.plot(train_fit_asp, color = 'red', label = 'fitted_values')\n",
    "plt.ylabel('AvgSP')\n",
    "plt.legend()\n",
    "plt.title('Training fit on AvgSP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction graph\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(predictions_asp, color = 'red', label = 'predicted_values')\n",
    "plt.plot(raw_values_asp[r:], color = 'blue', label = 'actual_values')\n",
    "plt.legend()\n",
    "plt.ylabel('AvgSP')\n",
    "plt.title('Predictions of AvgSP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting CustomerCount\n",
    "np.random.seed(4)\n",
    "\n",
    "#CC series\n",
    "series_cc = input_variables.CustomerCount\n",
    "\n",
    "# transform data to be stationary\n",
    "raw_values_cc = series_cc.values\n",
    "diff_values_cc = difference(raw_values_cc, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised_cc = timeseries_to_supervised(diff_values_cc, 1)\n",
    "supervised_values_cc = supervised_cc.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train_cc, test_cc = supervised_values_cc[0:-step], supervised_values_cc[-step:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler_cc, train_scaled_cc, test_scaled_cc = scale(train_cc, test_cc)\n",
    "\n",
    "# fit the model\n",
    "lstm_model_cc = fit_lstm(train_scaled_cc, 1, 100, 1)\n",
    "\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped_cc = train_scaled_cc[:, 0].reshape(len(train_scaled_cc), 1, 1)\n",
    "train_fit_cc = lstm_model_cc.predict(train_reshaped_cc, batch_size=1)\n",
    "\n",
    "train_reshaped_cc1 = []\n",
    "for i in range(len(train_fit_cc)):\n",
    "    train_reshaped_cc1.append(train_reshaped_cc[i][0])\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions_cc = list()\n",
    "for i in range(len(test_scaled_cc)):\n",
    "\t# make one-step forecast\n",
    "\tX_cc, y_cc = test_scaled_cc[i, 0:-1], test_scaled_cc[i, -1]\n",
    "\tyhat_cc = forecast_lstm(lstm_model_cc, 1, X_cc)\n",
    "\t# invert scaling\n",
    "\tyhat_cc = invert_scale(scaler_cc, X_cc, yhat_cc)\n",
    "\t# invert differencing\n",
    "\tyhat_cc = inverse_difference(raw_values_cc, yhat_cc, len(test_scaled_cc)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions_cc.append(yhat_cc)\n",
    "\texpected_cc = raw_values_cc[len(train_cc) + i + 1]\n",
    "\tprint('Day=%d, Predicted_cc=%f, Expected_cc=%f' % (i+1, yhat_cc, expected_cc))\n",
    "\n",
    "# report performance\n",
    "rmse_cc = sqrt(mean_squared_error(raw_values_cc[-step:], predictions_cc))\n",
    "print('Test RMSE: %.3f' % rmse_cc)\n",
    "\n",
    "# line plot of observed vs predicted\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(train_reshaped_cc1, color = 'blue', label = 'fitted_values')\n",
    "plt.plot(train_fit_cc, color = 'red', label = 'actual_values')\n",
    "plt.legend()\n",
    "plt.ylabel('CustomerCount')\n",
    "plt.title('Training fit on CustomerCount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction graph\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(predictions_cc, color = 'red', label = 'predicted_values')\n",
    "plt.plot(raw_values_cc[r:], color = 'blue', label = 'actual_values')\n",
    "plt.legend()\n",
    "plt.ylabel('CustomerCount')\n",
    "plt.title('Predictions of CustomerCount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up dataframes for demand prediction\n",
    "\n",
    "forecasted_iv = pd.DataFrame({'AvgSP':predictions_asp , 'OP':input_variables.OP[r:], 'CustomerCount':predictions_cc})\n",
    "\n",
    "training_iv = input_variables[0:r].values\n",
    "training_ov = output_variable[0:r].values\n",
    "test_iv = forecasted_iv.values\n",
    "test_ov = output_variable[r:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Demand Model\n",
    "\n",
    "def demand_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=3, kernel_initializer='normal', activation='linear', kernel_regularizer = regularizers.l1(l=0.1), activity_regularizer = regularizers.l1(l=0.1)))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='linear'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    #Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate Demand\n",
    "estimator = KerasRegressor(build_fn=demand_model)\n",
    "model_fit_d = estimator.fit(training_iv, training_ov, nb_epoch = 100, verbose = 0)\n",
    "training_fit_d = estimator.predict(training_iv)\n",
    "predictions_d = estimator.predict(test_iv)\n",
    "predicted_values_d = []\n",
    "for i in range(len(predictions_d)):\n",
    "    predicted_values_d.append(predictions_d[i])\n",
    "\n",
    "plt.figure(figsize = (12,8))    \n",
    "plt.plot(training_fit_d, color = 'red', label = 'fitted_values')\n",
    "plt.plot(training_ov, color = 'blue', label = 'actual_values')\n",
    "plt.legend()\n",
    "plt.ylabel('Demand')\n",
    "plt.title('Training fit on Demand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "\n",
    "rmse_demand = sqrt(mean_squared_error(test_ov, predicted_values_d))\n",
    "print(rmse_demand)\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(predicted_values_d, color = 'red', label = 'predicted_values')\n",
    "plt.plot(test_ov, color = 'blue', label = 'actual_values')\n",
    "plt.legend()\n",
    "plt.ylabel('Demand')\n",
    "plt.title('Predictions of Demand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up 3-day forecast scenario\n",
    "\n",
    "np.random.seed(5)\n",
    "#forecasts asp\n",
    "forecast_asp = []\n",
    "for i in range(3):\n",
    "    forecast = forecast_lstm(lstm_model_asp, 1, np.array([test_scaled_asp[-1, -1]]))\n",
    "    forecast_is = invert_scale(scaler_asp, np.array([test_scaled_asp[-1, -1]]), forecast)\n",
    "    forecast_id = inverse_difference(raw_values_asp, forecast_is, 1)\n",
    "    test_scaled_asp[:,-1]+=np.array([forecast])\n",
    "    forecast_asp.append(forecast_id)\n",
    "\n",
    "\n",
    "#forecasts cc\n",
    "forecast_cc = []\n",
    "for i in range(3):\n",
    "    forecast2 = forecast_lstm(lstm_model_cc, 1, np.array([test_scaled_cc[-1, -1]]))\n",
    "    forecast2_is = invert_scale(scaler_cc, np.array([test_scaled_cc[-1, -1]]), forecast2)\n",
    "    forecast2_id = inverse_difference(raw_values_cc, forecast2_is, 1)\n",
    "    test_scaled_cc[:,-1]+=np.array([forecast2])\n",
    "    forecast_cc.append(forecast2_id)\n",
    "    \n",
    "op1 = input('Enter onion AvgSP for f-day1:  ')\n",
    "op2 = input('Enter onion AvgSP for f-day2:  ')\n",
    "op3 = input('Enter onion AvgSP for f-day3:  ')\n",
    "\n",
    "\n",
    "forecast_op = [op1, op2, op3]\n",
    "\n",
    "further_forecast_iv = pd.DataFrame({'AvgSP':forecast_asp, 'OP':forecast_op, 'CustomerCount':forecast_cc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "\n",
    "fpredictions_d = estimator.predict(further_forecast_iv.values)\n",
    "fpredicted_values_d = []\n",
    "for i in range(len(fpredictions_d)):\n",
    "    fpredicted_values_d.append(fpredictions_d[i])\n",
    "    \n",
    "print('Forecast input:')\n",
    "print(further_forecast_iv)\n",
    "print('Demand Forecast:')\n",
    "print(fpredicted_values_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_variable.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
